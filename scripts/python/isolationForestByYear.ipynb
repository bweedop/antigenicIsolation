{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Predicting Antigenic Outliers by Year using an Isolation Forest\n",
    "\n",
    "Isolation forests are a method of finding outliers in a dataset using data partitioning. The method works by repetitively partitioning a random feature (of an n-dimensional dataset) between its minimum and maximum values until a sample is isolated or all samples in a partition have the same value. Samples that are higher up in the isolation forst tree are considered outliers where samples deeper in the tree data structure are less likely to be outliers. \n",
    "\n",
    "You can read more on the [wikipedia](https://en.wikipedia.org/wiki/Isolation_forest) or the documentation by [sci-kit learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html)\n",
    "\n",
    "This document details the process of predicting outliers (antigenically distinct sequences) in a series of years which are 'seen' step-wise manner. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions for plotting\r\n",
    "\r\n",
    "# Only get the first of each handle when plotting\r\n",
    "def unique_everseen(seq, key=None):\r\n",
    "    seen = set()\r\n",
    "    seen_add = seen.add\r\n",
    "    return [x for x,k in zip(seq,key) if not (k in seen or seen_add(k))]\r\n",
    "\r\n",
    "#  Returns tuple of handles, labels for axis ax, after reordering them to conform to the label order `order`, and if unique is True, after removing entries with duplicate labels.\r\n",
    "def reorder_legend(ax=None,order=None,unique=False):\r\n",
    "    if ax is None: ax=plt.gca()\r\n",
    "    handles, labels = ax.get_legend_handles_labels()\r\n",
    "    labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0])) # sort both labels and handles by labels\r\n",
    "    if order is not None: # Sort according to a given list (not necessarily complete)\r\n",
    "        keys=dict(zip(order,range(len(order))))\r\n",
    "        labels, handles = zip(*sorted(zip(labels, handles), key=lambda t,keys=keys: keys.get(t[0],np.inf)))\r\n",
    "    if unique:  labels, handles= zip(*unique_everseen(zip(labels,handles), key = labels)) # Keep only the first of each handle\r\n",
    "    ax.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.25,1))\r\n",
    "    return(handles, labels)\r\n",
    "\r\n",
    "### Helper functions for misc use\r\n",
    "\r\n",
    "# Get unique items in a list\r\n",
    "def unique(list):\r\n",
    "    unique_items=[]\r\n",
    "    for i in list:\r\n",
    "        if i not in unique_items:\r\n",
    "            unique_items.append(i)\r\n",
    "        else:\r\n",
    "            pass\r\n",
    "    return unique_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants used throughout cells\n",
    "\n",
    "# Colors for plotting by cluster\n",
    "CLUSTER_COLORS={'HK68':'dodgerblue',\n",
    "                'EN72':'magenta',\n",
    "                'VI75':'olive', \n",
    "                'TX77':'aqua', \n",
    "                'BK79':'red', \n",
    "                'SI87':'gold', \n",
    "                'BE89':'grey',\n",
    "                'BE92':'salmon', \n",
    "                'WU95':'teal', \n",
    "                'SY97':'maroon', \n",
    "                'FU02':'palegreen'}\n",
    "# All features in dataset\n",
    "FEATURES=['distRoot', 'branch_length', 'hydrophobicity', 'charge', 'boman', 'instability', 'isoelectric_point']\n",
    "# Features excluding phylogenetic measurements\n",
    "NO_PHYLO_FEATURES=['hydrophobicity', 'charge', 'boman', 'instability', 'isoelectric_point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path='../../data/processedData/sequence_physioproperties.csv'\n",
    "physio_data=pd.read_csv(file_path)\n",
    "\n",
    "# Get numerical features and scale them to zero mean and unit variance\n",
    "ss=StandardScaler()\n",
    "to_scale=physio_data[FEATURES]\n",
    "scaled_df=pd.DataFrame(ss.fit_transform(to_scale), \n",
    "                       columns=to_scale.columns)\n",
    "\n",
    "# Add the categorical variable back in\n",
    "scaled_df['cluster'] = physio_data['cluster']\n",
    "\n",
    "year=[x.split('/')[2] for x in physio_data['seq_id'].to_list()]\n",
    "for i in range(0, len(year)):\n",
    "    if int(year[i]) > 67:\n",
    "        year[i]=int('19'+year[i])\n",
    "    else:\n",
    "        year[i]=int('20'+year[i])\n",
    "\n",
    "physio_data = scaled_df\n",
    "physio_data['year']=year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first two clusters of data ('HK68' and 'EN72')\n",
    "initial_data=physio_data[physio_data['year'] < 1974]\n",
    "current_clusters=initial_data.groupby('cluster')\n",
    "\n",
    "# Plot distance from the root and hydrophobicity\n",
    "fig, ax = plt.subplots()\n",
    "for name, group in current_clusters:\n",
    "    ax.scatter(x=group['distRoot'], \n",
    "               y=group['hydrophobicity'],\n",
    "               c=CLUSTER_COLORS.get(name),\n",
    "               label=name)\n",
    "ax.legend(loc='upper right')\n",
    "reorder_legend(ax, CLUSTER_COLORS.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current_data to first two clusters of sequences\n",
    "current_data=initial_data.copy()\n",
    "seen_clusters=unique(initial_data['cluster'].to_list())\n",
    "\n",
    "#fig, axs = plt.subplots(3, 3, figsize=(12,10))\n",
    "\n",
    "SHAPE = {1: 'o',\n",
    "         -1: 'x'}\n",
    "\n",
    "nophylo_features_results = []\n",
    "\n",
    "plt_row=0\n",
    "plt_col=0\n",
    "    \n",
    "for y in range(1975, 2004):\n",
    "    next_data=physio_data[physio_data['year'] == y].copy()\n",
    "    n_test=next_data.shape[0]\n",
    "    \n",
    "    next_clusters=unique(next_data['cluster'].to_list())\n",
    "    next_clusters=[x for x in next_clusters if x not in seen_clusters]\n",
    "    if len(next_clusters) == 1:\n",
    "        mr_cluster=next_clusters[0]\n",
    "        seen_clusters.append(mr_cluster)\n",
    "    elif len(next_clusters) > 1:\n",
    "        print(y, next_clusters)\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if n_test == 0:\n",
    "        continue\n",
    "    else:\n",
    "        # Training the model\n",
    "        clf=IsolationForest(random_state=0)\n",
    "        clf.fit(current_data[NO_PHYLO_FEATURES])\n",
    "        \n",
    "        # Predicting whether the next set of data are outliers\n",
    "        y_pred=clf.predict(next_data[NO_PHYLO_FEATURES])\n",
    "        next_clusters=next_data['cluster'].to_list()\n",
    "        false_positive=0\n",
    "        true_positive=0\n",
    "        false_negative=0\n",
    "        true_negative=0\n",
    "        for i in range(0, len(y_pred)):\n",
    "            if next_clusters[i] == mr_cluster and y_pred[i] == -1:\n",
    "                true_positive += 1\n",
    "            elif next_clusters[i] == mr_cluster and y_pred[i] == 1:\n",
    "                false_negative += 1\n",
    "            elif next_clusters[i] != mr_cluster and y_pred[i] == -1:\n",
    "                false_positive += 1\n",
    "            else:\n",
    "                true_negative += 1\n",
    "        \n",
    "        print(f'{mr_cluster} ({y}): Accuracy: {(true_positive + true_negative)/(true_positive + true_negative + false_positive + false_negative):4f}')\n",
    "        # (TP + TN)/(TP + TN + FP + FN)\n",
    "        \n",
    "        print(next_clusters)\n",
    "        print(y_pred, '\\n')\n",
    "        \n",
    "        current_data=current_data.append(next_data)"
   ]
  }
 ]
}